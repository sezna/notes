
# How to design a ranking function  
## Defining Relevance
We need a computational, objective definition of relevance. We define a formalized definition of relevance as our _retrieval model_. 
### Similarity-based definitions (models)
* `f(q,d) = similarity(q,d)`. 
 * a vector-space model
### Probabilistic Model
* `f(q,d) = p(R = 1 | d,q)` where `R` is boolean
 * classic probabilistic model
 * language model
 * divergence from randomness model
### Probabilistic inference model
* `f(q,d) = probability that d implies q`
### Axiomatic Model
* `f(q,d)` must satisfy a set of constraints 


## Commonalities
These ideas all rely on the _bag of words_ concept. The scores are computed based on each individual word. The *Term Frequency*, or *TF*, is how many times a word appears in a document. If a document is short and the word appears often, then this is more significant than if the document is long. A sufficiently long document is naturally expected to contain lots of words. This TF can be relative to the *document frequency*, or *DF*. If a term "Alex" appears in every document 10 times, it is more significant that it appears 12 times in another document.

## Best models?
The four major models that are generally regarded as the state of the art are:
* Pivoted length normalization
* BM25
* Query Likelihood
* PL2

BM25 is the most popular.


# Summary
Designing ranking functions requires a computational definition of relevance. Many models are equally effective with no clear winner, and the state of the art ranking functions tend to rely on a bag of words representation, TF and DF, and document length.
